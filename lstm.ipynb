{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOYCbc9xsu8hhJzX/1kOEeJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VD0627/CP/blob/main/lstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "nYNKHBVVuMlA"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        text = f.read()\n",
        "    return text"
      ],
      "metadata": {
        "id": "vvYVEZ5nuxS4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "def load_data(file_path):\n",
        "    \"\"\"Loads data from a zip file and returns the text content.\n",
        "\n",
        "    Args:\n",
        "    file_path (str): The path to the zip file.\n",
        "\n",
        "    Returns:\n",
        "    str: The text content of the file within the zip archive.\n",
        "           Returns an empty string if any error occurs during extraction.\n",
        "    \"\"\"\n",
        "    text = \"\"\n",
        "    try:\n",
        "        with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
        "            # Assuming there's only one file in the zip, get the first filename\n",
        "            filename = zip_ref.namelist()[0]\n",
        "            with zip_ref.open(filename, 'r') as f:\n",
        "                text = f.read().decode('utf-8') # Decode after reading from zip\n",
        "    except (zipfile.BadZipFile, IndexError, UnicodeDecodeError) as e:\n",
        "        print(f\"Error reading file: {e}\")\n",
        "    return text"
      ],
      "metadata": {
        "id": "plrsh6plu-8n"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = load_data('hp.zip')"
      ],
      "metadata": {
        "id": "CUAeLkiCvn_7"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts([text])\n",
        "total_words = len(tokenizer.word_index) + 1"
      ],
      "metadata": {
        "id": "V6fhlGLVvIe_"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences = []\n",
        "tokens = tokenizer.texts_to_sequences([text])[0]\n",
        "seq_length = 50"
      ],
      "metadata": {
        "id": "kYoLiB4iv5Uz"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(seq_length, len(tokens)):\n",
        "    input_sequences.append(tokens[i - seq_length:i + 1])"
      ],
      "metadata": {
        "id": "9urikHCNv97D"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=seq_length + 1, padding='pre'))\n",
        "X, y = input_sequences[:, :-1], input_sequences[:, -1]\n",
        "y = tf.keras.utils.to_categorical(y, num_classes=total_words)"
      ],
      "metadata": {
        "id": "2LjoP4cxwBF4"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Embedding(input_dim=total_words, output_dim=100, input_length=seq_length),\n",
        "    LSTM(256, return_sequences=True),\n",
        "    LSTM(256),\n",
        "    Dense(total_words, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z27HfkEFwINX",
        "outputId": "ff46d248-cae8-4c45-824c-92b856d9cec2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "QrxjZngewSls"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X, y, epochs=20, batch_size=128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHPFEKRawX75",
        "outputId": "8c708442-7c12-48db-f074-9042e0325fd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 989ms/step - accuracy: 0.0360 - loss: 6.6168\n",
            "Epoch 2/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 999ms/step - accuracy: 0.0476 - loss: 5.8286\n",
            "Epoch 3/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - accuracy: 0.0538 - loss: 5.7651\n",
            "Epoch 4/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - accuracy: 0.0492 - loss: 5.7546\n",
            "Epoch 5/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 997ms/step - accuracy: 0.0508 - loss: 5.6511\n",
            "Epoch 6/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - accuracy: 0.0643 - loss: 5.4978\n",
            "Epoch 7/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 987ms/step - accuracy: 0.0961 - loss: 5.2291\n",
            "Epoch 8/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 1s/step - accuracy: 0.1146 - loss: 5.0366\n",
            "Epoch 9/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - accuracy: 0.1744 - loss: 4.6655\n",
            "Epoch 10/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 982ms/step - accuracy: 0.2045 - loss: 4.4705\n",
            "Epoch 11/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 985ms/step - accuracy: 0.2276 - loss: 4.2652\n",
            "Epoch 12/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 1s/step - accuracy: 0.2566 - loss: 4.0630\n",
            "Epoch 13/20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(seed_text, next_words=50, temperature=1.0):\n",
        "    for _ in range(next_words):\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=seq_length, padding='pre')\n",
        "\n",
        "        predicted_probs = model.predict(token_list, verbose=0)[0]\n",
        "        predicted_probs = np.log(predicted_probs) / temperature  # Adjust randomness\n",
        "        predicted_probs = np.exp(predicted_probs) / np.sum(np.exp(predicted_probs))\n",
        "        predicted_index = np.random.choice(range(len(predicted_probs)), p=predicted_probs)\n",
        "\n",
        "        output_word = tokenizer.index_word.get(predicted_index, \"\")\n",
        "        seed_text += \" \" + output_word\n",
        "\n",
        "    return seed_text"
      ],
      "metadata": {
        "id": "hzsta6bw3HQt"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text(\"harry looked at\", next_words=50, temperature=0.7))"
      ],
      "metadata": {
        "id": "70Z02vS73In6",
        "outputId": "3dae1de8-95e2-4193-dfef-0938433b5595",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "harry looked at magical arts  dragon 1993 magical studies of magic magic dark dragon the office 1992 ravenclaw the arts  dragon 1993 hufflepuff of magic in the department of magical 21 assistant \r pre 1970s \r arts 60 august 1960 neville durmstrang male student head gryffindor unknown unknown human  pure blood or half blood black grey dumbledore's army\n"
          ]
        }
      ]
    }
  ]
}